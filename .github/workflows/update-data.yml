name: Update Real Estate Data

on:
  schedule:
    - cron: '0 0 * * 0'
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install pandas

      - name: Download county CSV
        run: |
          curl -L "https://econdata.s3-us-west-2.amazonaws.com/Reports/Core/RDC_Inventory_Core_Metrics_County_History.csv" \
            -o /tmp/county_full.csv

      - name: Download zip CSV
        run: |
          curl -L "https://econdata.s3-us-west-2.amazonaws.com/Reports/Core/RDC_Inventory_Core_Metrics_Zip_History.csv" \
            -o /tmp/zip_full.csv

      - name: Split CSVs by state
        run: |
          python3 - << 'PYEOF'
          import pandas as pd
          import os

          FIPS_TO_STATE = {
            1:'AL',2:'AK',4:'AZ',5:'AR',6:'CA',8:'CO',9:'CT',10:'DE',
            11:'DC',12:'FL',13:'GA',15:'HI',16:'ID',17:'IL',18:'IN',19:'IA',
            20:'KS',21:'KY',22:'LA',23:'ME',24:'MD',25:'MA',26:'MI',27:'MN',
            28:'MS',29:'MO',30:'MT',31:'NE',32:'NV',33:'NH',34:'NJ',35:'NM',
            36:'NY',37:'NC',38:'ND',39:'OH',40:'OK',41:'OR',42:'PA',44:'RI',
            45:'SC',46:'SD',47:'TN',48:'TX',49:'UT',50:'VT',51:'VA',53:'WA',
            54:'WV',55:'WI',56:'WY',72:'PR'
          }

          os.makedirs('data/county', exist_ok=True)
          os.makedirs('data/zip', exist_ok=True)

          print("Processing county data...")
          county_df = pd.read_csv('/tmp/county_full.csv', dtype={'county_fips': str})
          county_df['county_fips'] = county_df['county_fips'].str.zfill(5)
          county_df['state_fips'] = county_df['county_fips'].str[:2].astype(int)
          county_df['state'] = county_df['state_fips'].map(FIPS_TO_STATE)
          county_df = county_df.dropna(subset=['state']).drop(columns=['state_fips'])
          for state, group in county_df.groupby('state'):
            group.drop(columns=['state']).to_csv('data/county/' + state + '.csv', index=False)
          print("County files written: " + str(county_df['state'].nunique()))

          print("Processing zip data...")
          zip_df = pd.read_csv('/tmp/zip_full.csv', dtype={'postal_code': str})
          zip_df['postal_code'] = zip_df['postal_code'].str.zfill(5)
          def extract_state(z):
            if pd.isna(z): return None
            parts = str(z).split(',')
            return parts[-1].strip().upper() if len(parts) >= 2 else None
          zip_df['state'] = zip_df['zip_name'].apply(extract_state)
          valid = set(FIPS_TO_STATE.values())
          zip_df = zip_df.dropna(subset=['state'])
          zip_df = zip_df[zip_df['state'].isin(valid)]
          for state, group in zip_df.groupby('state'):
            group.drop(columns=['state']).to_csv('data/zip/' + state + '.csv', index=False)
          print("Zip files written: " + str(zip_df['state'].nunique()))
          PYEOF

      - name: Show file sizes
        run: |
          echo "Largest county files:"; ls -lh data/county/ | sort -k5 -rh | head -5
          echo "Largest zip files:"; ls -lh data/zip/ | sort -k5 -rh | head -5

      - name: Update timestamp
        run: echo "Last refreshed $(date -u +%Y-%m-%dT%H:%M:%SZ)" > data/last_updated.txt

      - name: Commit and push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/
          git diff --staged --quiet || git commit -m "Data split by state $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          git push
